# ğŸª„ è°ƒå‚é­”æ³•ï¼šç”¨PEFTç®€åŒ–å¤§å‹è¯­è¨€æ¨¡å‹

å—¨ï¼ŒæŠ€æœ¯å·«å¸ˆä»¬ï¼ğŸ§™â€â™€ï¸ æ¬¢è¿æ¥åˆ°å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰çš„é­”æ³•ä¸–ç•Œï¼Œé€šè¿‡æç¤ºè°ƒä¼˜ï¼ˆPrompt Tuningï¼‰æ¥å¢å¼ºæˆ‘ä»¬çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œæ— éœ€è¿›è¡Œå®Œæ•´çš„å¾®è°ƒå°±èƒ½è½»æ¾æå‡ï¼

## ğŸŒŸ é«˜æ•ˆå¾®è°ƒçš„æ¢ç´¢ä¹‹æ—…
é€šè¿‡LoRAï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§é«˜æ•ˆæ›´æ–°æ¨¡å‹æƒé‡çš„èªæ˜æ–¹æ³•ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿›å…¥åŠ æ€§æ–¹æ³•çš„é¢†åŸŸï¼Œæ— éœ€æ”¹å˜æ¨¡å‹çš„æƒé‡å°±èƒ½æå‡æ€§èƒ½ã€‚

### ğŸ”‘ æç¤ºè°ƒä¼˜ï¼šæ–°ç‚¼é‡‘æœ¯
ä¸è°ƒæ•´æªè¾ä»¥æ›´å¥½åœ°ç†è§£ä»»åŠ¡çš„æç¤ºå·¥ç¨‹ä¸åŒï¼Œæç¤ºè°ƒä¼˜åœ¨æç¤ºæœ¬èº«å¼•å…¥äº†å¯è®­ç»ƒçš„æ ‡è®°ï¼Œè®©æ¨¡å‹é€šè¿‡ç›‘ç£å­¦ä¹ æ‰¾åˆ°å®ƒä»¬çš„æœ€ä¼˜å€¼ã€‚

## ğŸ§¬ è½¯æç¤ºåŸºå› ç»„ï¼šé‡Šæ”¾è™šæ‹Ÿæ ‡è®°
- **è½¯æç¤º**ï¼šä¸€ç»„é¢å¤–çš„æ ‡è®°ï¼Œç¥å¥‡åœ°å‰ç½®åˆ°ä½ çš„è¾“å…¥æ–‡æœ¬çš„åµŒå…¥å‘é‡ä¸Šã€‚
- **è™šæ‹Ÿæ ‡è®°**ï¼šä¸è‡ªç„¶è¯­è¨€çš„å›ºå®šæ ‡è®°ä¸åŒï¼Œè¿™äº›å¯ä»¥å˜æˆåµŒå…¥ç©ºé—´å†…çš„ä»»ä½•å€¼ï¼Œä¼˜åŒ–ä»»åŠ¡æ€§èƒ½ã€‚

## ğŸ“Š æ€§èƒ½æ¯”è¾ƒï¼šæç¤ºè°ƒä¼˜ vs. å®Œæ•´å¾®è°ƒ
- **è¾ƒå°çš„LLMs**ï¼šæç¤ºè°ƒä¼˜å¯èƒ½æ— æ³•è¶…è¶Šå®Œæ•´å¾®è°ƒã€‚
- **è¾ƒå¤§çš„LLMs**ï¼šéšç€æ¨¡å‹å¤§å°çš„å¢åŠ ï¼Œæç¤ºè°ƒä¼˜çš„èƒ½åŠ›ä¹Ÿéšä¹‹å¢å¼ºï¼Œä¸å®Œæ•´å¾®è°ƒçš„åŠ›é‡ç›¸åª²ç¾ã€‚

### ğŸ“ˆ SuperGLUEå¾—åˆ†ï¼šåŸºå‡†æµ‹è¯•
çœ‹çœ‹æç¤ºè°ƒä¼˜åœ¨SuperGLUEåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å¦‚ä½•ï¼Œè¿™æ˜¯å¯¹LLMsè¯­è¨€èƒ½åŠ›çš„çœŸæ­£è€ƒéªŒã€‚

## ğŸ’¡ å¯è§£é‡Šæ€§æŒ‘æˆ˜ï¼šè§£å¼€è½¯æç¤ºçš„å¥¥ç§˜
è™½ç„¶è½¯æç¤ºæ ‡è®°ä¸å¯¹åº”å·²çŸ¥çš„è¯æ±‡ï¼Œä½†å®ƒä»¬å½¢æˆäº†è¯­ä¹‰ç°‡ï¼Œæš—ç¤ºäº†å®ƒä»¬å­¦ä¹ ç±»ä¼¼è¯æ±‡çš„è¡¨ç¤ºèƒ½åŠ›ã€‚

## ğŸ”® æ€»ç»“ï¼šPEFTåœ¨LLMè®­ç»ƒä¸­çš„é­”æ³•
LoRAå’Œæç¤ºè°ƒä¼˜æ˜¯ä½ çš„PEFTå·¥å…·åŒ…ï¼Œå…è®¸ä½ ä»¥æ½œåœ¨çš„æ€§èƒ½æå‡ä¸ºç›®æ ‡å¾®è°ƒæ¨¡å‹ï¼ŒåŒæ—¶åªä½¿ç”¨ä¸€å°éƒ¨åˆ†è®¡ç®—èµ„æºã€‚

### ğŸš€ ç¬¬äºŒå‘¨å›é¡¾
- **æŒ‡ä»¤å¾®è°ƒ**ï¼šç”¨å‡ ç™¾ä¸ªç¤ºä¾‹é€‚åº”åŸºç¡€æ¨¡å‹ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šä½¿ç”¨ROUGEå’ŒHELMæ¥è¡¡é‡æ¨¡å‹æˆåŠŸã€‚
- **PEFT**ï¼šæœ€å°åŒ–è®¡ç®—å’Œå†…å­˜èµ„æºï¼ŒåŠ é€Ÿä½ çš„å¼€å‘è¿‡ç¨‹ã€‚

åˆ«å¿˜äº†è®¢é˜…ï¼Œä»¥è·å–æ›´å¤šå…³äºAIå‰æ²¿çš„è¿·äººæ¢ç´¢ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå¼•å¯¼ä½ ç©¿è¶Šæ¨¡å‹æ•ˆç‡çš„ç¥ç§˜é¢†åŸŸåŠå…¶ä¹‹å¤–ï¼

ğŸ‘‹ ä¸‹æ¬¡è§ï¼Œç»§ç»­å®éªŒï¼Œç»§ç»­åˆ›æ–°ï¼Œæ„¿ä½ çš„æ¨¡å‹æ°¸è¿œç²¾å‡†è°ƒä¼˜è‡³å®Œç¾ï¼

---

[åŠ å…¥æˆ‘ä»¬ï¼Œæ·±å…¥äº†è§£PEFTå’ŒAIçš„å¥¥å¾·èµ›ï¼](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---

# ğŸª„ The Magic of Prompt Tuning: Streamline LLMs with PEFT

Hey Tech Sorcerers! ğŸ§™â€â™€ï¸ Welcome to the wizardry of Parameter Efficient Fine-Tuning (PEFT) with Prompt Tuning. Today, we're weaving spells to enhance our Large Language Models (LLMs) without the heavy lifting of full fine-tuning!

## ğŸŒŸ The Quest for Efficient Fine-Tuning
With LoRA, we discovered a clever way to update model weights efficiently. Now, let's venture into the realm of additive methods, where we improve performance without altering the model's weights at all.

### ğŸ”‘ Prompt Tuning: The New Alchemy
Unlike prompt engineering, which tweaks the wording for better task understanding, prompt tuning introduces trainable tokens to the prompt itself, letting the model find their optimal values through supervised learning.

## ğŸ§¬ The Soft Prompt Genome: Virtual Tokens Unleashed
- **Soft Prompts**: A set of additional tokens that get magically prepended to your input text's embedding vectors.
- **Virtual Tokens**: Unlike natural language's fixed tokens, these can morph into any value within the embedding space, optimizing for task performance.

## ğŸ“Š Comparing Performance: Prompt Tuning vs. Full Fine-Tuning
- **Smaller LLMs**: Prompt tuning may not outshine full fine-tuning.
- **Larger LLMs**: As model size grows, so does the prowess of prompt tuning, rivaling the might of full fine-tuning.

### ğŸ“ˆ SuperGLUE Scores: The Benchmark
See how prompt tuning measures up against full fine-tuning and other methods on the SuperGLUE benchmark, a true test of an LLM's linguistic prowess.

## ğŸ’¡ The Interpretability Challenge: Unraveling Soft Prompts
While soft prompt tokens don't correspond to known words, they form semantic clusters, hinting at their ability to learn word-like representations.

## ğŸ”® Wrapping Up: PEFT's Enchantment in LLM Training
LoRA and Prompt Tuning are your PEFT toolkit, allowing you to fine-tune models with the potential for improved performance on tasks, all while using a fraction of the compute resources.

### ğŸš€ Recap of Week 2
- **Instruction Fine-Tuning**: Adapting foundation models with a few hundred examples.
- **Evaluation Metrics**: Utilizing ROUGE and HELM to gauge model success.
- **PEFT**: Minimizing compute and memory resources, accelerating your development process.

Don't forget to subscribe for more enchanting explorations into the AI frontier. We're here to guide you through the mystical realms of model efficiency and beyond!

ğŸ‘‹ Until next time, keep experimenting, keep innovating, and may your models always be finely tuned to perfection!

---

[Join us for more on PEFT and the AI odyssey!](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---

# ç§‘æ™®æŠ€æœ¯æ–‡ç« ï¼šæ¢ç´¢å‚æ•°é«˜æ•ˆå¾®è°ƒâ€”â€”LoRAä¸Prompt Tuning

## å¼•è¨€
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¾®è°ƒæ˜¯ä¸€ä¸ªèµ„æºå¯†é›†å‹çš„è¿‡ç¨‹ã€‚å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯ï¼Œå¦‚LoRAå’ŒPrompt Tuningï¼Œæä¾›äº†ä¸€ç§å‡å°‘è®¡ç®—èµ„æºéœ€æ±‚çš„æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡æ¨¡å‹æ€§èƒ½ã€‚

## LoRAâ€”â€”ä½ç§©é€‚åº”å¾®è°ƒ
LoRAé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥æ›´æ–°æ¨¡å‹æƒé‡ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ‰€æœ‰å‚æ•°ã€‚è¿™ç§æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹å‚æ•°æ•°é‡ä¸å˜çš„æƒ…å†µä¸‹ï¼Œå‡å°‘äº†è®­ç»ƒæ—¶çš„è®¡ç®—é‡ã€‚

## Prompt Tuningâ€”â€”æç¤ºè°ƒæ•´å¾®è°ƒ
ä¸LoRAä¸åŒï¼ŒPrompt Tuningä¸æ”¹å˜æ¨¡å‹æƒé‡ï¼Œè€Œæ˜¯åœ¨æç¤ºä¸­æ·»åŠ å¯è®­ç»ƒçš„è™šæ‹Ÿæ ‡è®°ï¼ˆè½¯æç¤ºï¼‰ã€‚è¿™äº›è½¯æç¤ºé€šè¿‡ç›‘ç£å­¦ä¹ è¿‡ç¨‹æ¥ç¡®å®šå…¶æœ€ä¼˜å€¼ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹å¯¹ç‰¹å®šä»»åŠ¡çš„å®Œæˆã€‚

## Prompt Tuningä¸Prompt Engineeringçš„åŒºåˆ«
Prompt Engineeringä¾§é‡äºé€šè¿‡è°ƒæ•´æç¤ºçš„è¯­è¨€æ¥æ”¹å–„æ¨¡å‹çš„è¾“å‡ºï¼Œè€ŒPrompt Tuningåˆ™æ˜¯é€šè¿‡æ·»åŠ å¯è®­ç»ƒçš„è½¯æç¤ºæ¥è®©æ¨¡å‹è‡ªå·±å­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å®Œæˆä»»åŠ¡ã€‚

## Prompt Tuningçš„æ€§èƒ½
Prompt Tuningåœ¨è¾ƒå°çš„LLMsä¸Šçš„æ€§èƒ½å¯èƒ½ä¸å¦‚å…¨å‚æ•°å¾®è°ƒï¼Œä½†åœ¨æ¨¡å‹å‚æ•°é‡è¾¾åˆ°ä¸€å®šè§„æ¨¡åï¼Œå…¶æ€§èƒ½å¯ä»¥ä¸å…¨å‚æ•°å¾®è°ƒç›¸åª²ç¾ï¼ŒåŒæ—¶æ˜¾è‘—ä¼˜äºä»…ä½¿ç”¨Prompt Engineeringçš„æ–¹æ³•ã€‚

## è½¯æç¤ºçš„è§£é‡Šæ€§
è½¯æç¤ºçš„å€¼åœ¨è¿ç»­çš„åµŒå…¥å‘é‡ç©ºé—´å†…å¯ä»¥æ˜¯ä»»ä½•å€¼ï¼Œè¿™å¯èƒ½å¸¦æ¥è§£é‡Šæ€§ä¸Šçš„æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œå¯¹è½¯æç¤ºæœ€è¿‘é‚»çš„åˆ†ææ˜¾ç¤ºï¼Œå®ƒä»¬å½¢æˆäº†ç´§å¯†çš„è¯­ä¹‰ç°‡ï¼Œè¡¨æ˜è¿™äº›æç¤ºå­¦ä¹ åˆ°äº†ä¸ä»»åŠ¡ç›¸å…³çš„è¯æ±‡è¡¨ç¤ºã€‚

## LoRAä¸Prompt Tuningçš„å®è·µåº”ç”¨
LoRAå› å…¶ä¸å…¨å‚æ•°å¾®è°ƒç›¸å½“çš„æ€§èƒ½è€Œè¢«å¹¿æ³›ä½¿ç”¨ã€‚åŒæ—¶ï¼ŒPrompt Tuningæä¾›äº†ä¸€ç§åœ¨ä¸æ”¹å˜æ¨¡å‹æƒé‡çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡è®­ç»ƒå°‘é‡å‚æ•°æ¥é€‚åº”æ–°ä»»åŠ¡çš„é«˜æ•ˆç­–ç•¥ã€‚

## ç»“è¯­
é€šè¿‡LoRAå’ŒPrompt Tuningï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¤§å¹…åº¦å‡å°‘è®¡ç®—èµ„æºéœ€æ±‚çš„åŒæ—¶ï¼Œå¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæœ‰æ•ˆçš„å¾®è°ƒã€‚è¿™äº›PEFTæŠ€æœ¯ä¸ä»…åŠ å¿«äº†å¼€å‘è¿‡ç¨‹ï¼Œè¿˜å…è®¸å¼€å‘è€…åœ¨æœ‰é™çš„è®¡ç®—é¢„ç®—ä¸‹æœ€å¤§åŒ–æ¨¡å‹æ€§èƒ½ã€‚

---

æœ¬æ–‡ä¸ºè¯»è€…æä¾›äº†LoRAå’ŒPrompt TuningæŠ€æœ¯çš„æ·±å…¥ç†è§£ï¼Œå¸®åŠ©ä»–ä»¬åœ¨å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­åšå‡ºæ›´é«˜æ•ˆçš„æŠ€æœ¯é€‰æ‹©ã€‚

---

[åŠ å…¥æˆ‘ä»¬ï¼Œè·å–æ›´å¤šå…³äºLoRAå’ŒAIå¥¥å¾·èµ›çš„å†…å®¹ï¼](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---
