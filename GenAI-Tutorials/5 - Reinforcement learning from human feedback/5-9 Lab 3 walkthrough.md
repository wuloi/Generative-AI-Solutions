# ğŸ§ª **å®éªŒå®¤3è§£æï¼šç”¨RLHFå’ŒPPOä¸ºLLMsè§£æ¯’**

æŠ€æœ¯çˆ±å¥½è€…ä»¬ï¼Œä½ ä»¬å¥½ï¼ğŸ‘‹ å‡†å¤‡æŒ½èµ·ç¼–ç çš„è¢–å­ï¼Œæ·±å…¥å®éªŒå®¤3ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œæµ‹è¯•æˆ‘ä»¬çš„äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰çŸ¥è¯†ã€‚Chriså°†å¼•å¯¼ä½ ç©¿è¶Šå¾®è°ƒçš„æˆ˜å£•ï¼Œä½¿ç”¨PPOä½¿æˆ‘ä»¬çš„AIæ¨¡å‹ä¸ä»…æ™ºèƒ½ï¼Œè€Œä¸”éå¸¸å°Šé‡ä»–äººä¸”æ— æ¯’ã€‚ğŸ› ï¸

## **æ¬¢è¿æ¥åˆ°å®éªŒå®¤3ï¼šRLHFå·¥ä½œåŠ**
åœ¨è¿™ä¸ªå®éªŒå®¤ä¸­ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨å®éªŒå®¤2çš„è¾“å‡ºï¼Œå¹¶ä½¿ç”¨å¸¦æœ‰ä»‡æ¨è¨€è®ºå¥–åŠ±æ¨¡å‹çš„RLHFè¿›è¡Œå¾®è°ƒï¼Œä»¥é™ä½æ¯’æ€§ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¼˜åŒ–â€œéä»‡æ¨â€ï¼

## **ç”¨Pythonåº“æ­å»ºèˆå°**
æˆ‘ä»¬æ­£åœ¨åŠ è½½PyTorchã€transformersï¼Œè¿˜æœ‰ä¸€ä¸ªæ–°è§’è‰²â€”trlï¼Œå®ƒè®©æˆ‘ä»¬å¯ä»¥ä½¿ç”¨PPOç®—æ³•ã€‚æ˜¯æ—¶å€™å¯¼å…¥æˆ‘ä»¬çš„å·¥å…·å¹¶å¼€å§‹ç¼–ç äº†ï¼

## **ä»‹ç»FacebookäºŒå…ƒåˆ†ç±»å™¨**
é‡è§AutoModelForSeq1Classificationï¼Œæˆ‘ä»¬åŠ è½½FacebookäºŒå…ƒåˆ†ç±»å™¨çš„ç§˜å¯†æ­¦å™¨ï¼Œç”¨äºæ£€æµ‹ä»‡æ¨è¨€è®ºã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–â€œéä»‡æ¨â€ï¼

## **å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰çš„åŠ›é‡**
è¿˜è®°å¾—å®éªŒå®¤2ä¸­çš„PEFTå—ï¼Ÿæˆ‘ä»¬ç»§ç»­ä½¿ç”¨å®ƒï¼Œåªè®­ç»ƒæˆ‘ä»¬æ¨¡å‹å¤§å°çš„ä¸€å°éƒ¨åˆ†â€”ä»…æœ‰1.4%ï¼Œä¿æŒæˆ‘ä»¬çš„æ¨¡å‹ç²¾ç®€é«˜æ•ˆã€‚

## **ä½¿ç”¨TRLåˆ›å»ºå‚è€ƒæ¨¡å‹**
æˆ‘ä»¬ä½¿ç”¨TRLåˆ›å»ºä¸€ä¸ªå‚è€ƒæ¨¡å‹ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çš„PPOè®­ç»ƒåœ¨æ­£ç¡®çš„è½¨é“ä¸Šï¼Œä½¿ç”¨KLæ•£åº¦é˜²æ­¢æˆ‘ä»¬çš„æ¨¡å‹åç¦»è½¨é“ã€‚

## **æ¯’æ€§è¯„ä¼°ï¼šå‰åå¯¹æ¯”**
æˆ‘ä»¬æ­£åœ¨è®¾ç½®ä¸€ä¸ªè¯„ä¼°æœºåˆ¶ï¼Œä½¿ç”¨Evaluateåº“æ¥è¡¡é‡PPOè¿‡ç¨‹å‰åæ¨¡å‹è¾“å‡ºçš„æ¯’æ€§ã€‚

## **ä½¿ç”¨PPOè¿›è¡Œå¾®è°ƒï¼šä¸»è¦äº‹ä»¶**
æ˜¯æ—¶å€™åˆå§‹åŒ–PPOTrainerï¼Œè®©æˆ‘ä»¬çš„æ¨¡å‹å‡†å¤‡å¥½è¿›è¡Œä¸€äº›ä¸¥è‚ƒçš„å¾®è°ƒã€‚æˆ‘ä»¬åƒé¹°ä¸€æ ·ç›¯ç€KLæ•£åº¦ï¼Œç¡®ä¿æˆ‘ä»¬çš„æ›´æ–°ä¿æŒåœ¨æ­£ç¡®çš„è½¨é“ä¸Šã€‚

## **Hugging Faceæ¨ç†ç®¡é“ï¼šç®€åŒ–æˆ‘ä»¬çš„è¿‡ç¨‹**
æˆ‘ä»¬åˆ©ç”¨hugging faceæ¨ç†ç®¡é“æ¥ç®€åŒ–æˆ‘ä»¬çš„è¿‡ç¨‹ï¼Œä¸“æ³¨äºæˆ‘ä»¬å®éªŒå®¤çš„RLæ–¹é¢ã€‚

## **å®šé‡å’Œå®šæ€§æ¯”è¾ƒï¼šè¡¡é‡æˆåŠŸ**
PPOè®­ç»ƒåï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒæ¨¡å‹çš„æ¯’æ€§å¾—åˆ†åœ¨è¿‡ç¨‹å‰åçš„å˜åŒ–ï¼Œç›®æ ‡æ˜¯æ˜¾è‘—é™ä½ã€‚

## **æ€»ç»“å®éªŒå®¤3ï¼šè¿ˆå‘æ›´æ¸…æ´ã€æ›´å®‰å…¨çš„AI**
åœ¨è¿™ä¸ªå®éªŒå®¤ä¸­æˆ‘ä»¬æ¶µç›–äº†å¾ˆå¤šå†…å®¹ï¼Œä½†çœŸæ­£çš„æ”¶è·æ˜¯RLHFå’ŒPPOåœ¨ä½¿AIæ¨¡å‹æ›´å®‰å…¨ã€æ›´ç¬¦åˆæˆ‘ä»¬ä»·å€¼è§‚æ–¹é¢çš„å®é™…åº”ç”¨ã€‚

---

åŠ å…¥æˆ‘ä»¬ï¼Œç»§ç»­æ¢ç´¢AIå¯¹é½çš„å‰æ²¿ä¸–ç•Œã€‚åˆ«å¿˜äº†ç‚¹å‡»è®¢é˜…æŒ‰é’®ï¼Œè·å–æ›´å¤šæ·±å…¥çš„æŠ€æœ¯æ´å¯Ÿã€‚ä¸‹æ¬¡è§ï¼Œç»§ç»­ç¼–ç ï¼Œè®©æˆ‘ä»¬ç»§ç»­æ¨åŠ¨AIçš„å¯èƒ½æ€§è¾¹ç•Œï¼ğŸŒŸ

---

[åŠ å…¥æˆ‘ä»¬ï¼Œæ¢ç´¢æ›´å¤šAIï¼](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---

# ğŸ§ª **Lab 3 Breakdown: Detoxifying LLMs with RLHF and PPO**

Hey tech enthusiasts! ğŸ‘‹ Get ready to roll up your coding sleeves and dive into Lab 3, where we're putting our Reinforcement Learning from Human Feedback (RLHF) knowledge to the test. Chris is here to guide you through the trenches of fine-tuning with PPO to make our AI models not only smart but super respectful and non-toxic. ğŸ› ï¸

## **Welcome to Lab 3: The RLHF Workshop**
In this lab, we're taking the output from Lab 2 and fine-tuning it to lower toxicity using RLHF with a hate speech reward model. We're all about optimizing for 'not hate' here!

## **Setting the Stage with Python Libraries**
We're loading up on PyTorch, transformers, and a new playerâ€”trl, which gives us access to the PPO algorithm. It's time to import our tools and get coding!

## **Introducing the Facebook Binary Classifier**
Meet the AutoModelForSeq1Classification, our secret weapon for loading the Facebook binary classifier that detects hate speech. We're all about maximizing 'not hate'!

## **The Power of Parameter-Efficient Fine-Tuning (PEFT)**
Remember PEFT from Lab 2? We're sticking with it, training a tiny percentage of our model sizeâ€”just 1.4%, keeping our models lean and efficient.

## **Creating a Reference Model with TRL**
We're using TRL to create a reference model that keeps our PPO training in check, using KL divergence to prevent our model from going off the rails.

## **Toxicity Evaluation: Before and After**
We're setting up an evaluation mechanism using the Evaluate library to measure the toxicity of our model's output before and after the PPO process.

## **Fine-Tuning with PPO: The Main Event**
It's time to initialize the PPOTrainer and get our model ready for some serious fine-tuning. We're watching that KL divergence like a hawk to keep our updates on track.

## **The Hugging Face Inference Pipeline: Streamlining Our Process**
We're making use of the hugging face inference pipeline to simplify our process, focusing on the RL aspect of our lab.

## **Quantitative and Qualitative Comparison: Measuring Success**
After the PPO training, we'll compare our model's toxicity score before and after the process, aiming for a significant reduction.

## **Wrapping Up Lab 3: Onwards to Cleaner, Safer AI**
We've covered a lot in this lab, but the real takeaway is the practical application of RLHF and PPO in making AI models that are safer and more aligned with our values.

---

Join us as we continue to explore the cutting-edge world of AI alignment. Don't forget to hit that subscribe button for more in-depth tech insights. Until next time, keep coding, and let's keep pushing the boundaries of what AI can be! ğŸŒŸ

[Check out the full lab experience in our next video](https://www.youtube.com/watch?v=rlhf-lab-3-detoxifying-llms)

---

[Join us for more AI explorations!](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---

# ç§‘æ™®æŠ€æœ¯æ–‡ç« ï¼šé€šè¿‡RLHFé™ä½AIæ¨¡å‹çš„æ¯’æ€§

## å¼•è¨€
åœ¨äººå·¥æ™ºèƒ½çš„ä¸–ç•Œé‡Œï¼Œç¡®ä¿æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¾“å‡ºæ—¢æ™ºèƒ½åˆå®‰å…¨æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨ä¸€ç§ç§°ä¸ºå¼ºåŒ–å­¦ä¹ ä¸äººç±»åé¦ˆï¼ˆRLHFï¼‰çš„æŠ€æœ¯æ¥é™ä½è¯­è¨€æ¨¡å‹çš„æ¯’æ€§ã€‚

## RLHFå®éªŒå®¤å®è·µ
Chrisä¸ºæˆ‘ä»¬å‡†å¤‡äº†ä¸€ä¸ªå®éªŒå®¤ç»ƒä¹ ï¼Œè®©æˆ‘ä»¬äº²æ‰‹å®è·µRLHFã€‚åœ¨è¿™ä¸ªå®éªŒå®¤ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºé™ä½ä¹‹å‰å¾®è°ƒæ¨¡å‹çš„æ¯’æ€§ï¼Œä½¿ç”¨ä»‡æ¨è¨€è®ºå¥–åŠ±æ¨¡å‹æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œä½¿å…¶ç”Ÿæˆéä»‡æ¨è¨€è®ºçš„è¾“å‡ºã€‚

## å‡†å¤‡å·¥ä½œï¼šå®‰è£…Pythonåº“
æˆ‘ä»¬å°†ä½¿ç”¨PyTorchã€transformersåº“ã€æ•°æ®é›†åº“ã€è¯„ä¼°åº“ï¼ˆevaluateï¼‰ä»¥åŠPEFTï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰åº“ã€‚æ–°å¼•å…¥çš„trlåº“å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨PPOç®—æ³•ã€‚

## å¼•å…¥æ–°å·¥å…·ï¼štrlå’ŒPPO
åœ¨æœ¬æ¬¡å®éªŒå®¤ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨PPOç®—æ³•æ¥æ›´æ–°æ¨¡å‹æƒé‡ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»åå¥½ã€‚trlåº“æä¾›äº†PPOTrainerå’Œè®­ç»ƒå‚æ•°ï¼Œå®ƒä»¬éµå¾ªhugging faceçš„trainerå’Œè®­ç»ƒå‚æ•°çš„æƒ¯ä¾‹ã€‚

## æ•°æ®é›†ä¸æ¨¡å‹
æˆ‘ä»¬å°†åŠ è½½æ•°æ®é›†å’Œæ¨¡å‹ï¼Œä½¿ç”¨LengthSampleræ¥ç­›é€‰æ–‡æœ¬é•¿åº¦ï¼Œç¡®ä¿æ–‡æœ¬åœ¨å¤„ç†æ—¶ä¸ä¼šè¶…è¿‡æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€‚

## å¾®è°ƒè¿‡ç¨‹
å¾®è°ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Facebookçš„äºŒå…ƒåˆ†ç±»å™¨æ¥æ£€æµ‹ä»‡æ¨è¨€è®ºã€‚è¿™ä¸ªåˆ†ç±»å™¨å°†å¸®åŠ©æˆ‘ä»¬åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«ä»‡æ¨è¨€è®ºï¼Œå¹¶ä¸ºæˆ‘ä»¬çš„PPOè®­ç»ƒæä¾›å¿…è¦çš„åé¦ˆã€‚

## PPOè®­ç»ƒ
åœ¨PPOè®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å‚è€ƒæ¨¡å‹å’ŒKLæ•£åº¦æ¥ç¡®ä¿æ¨¡å‹åœ¨ä¼˜åŒ–å¥–åŠ±çš„åŒæ—¶ï¼Œä¸åç¦»åŸå§‹æ¨¡å‹çš„è¾“å‡ºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥é˜²æ­¢æ¨¡å‹çš„å¥–åŠ±é»‘å®¢æ”»å‡»ï¼Œç¡®ä¿æ¨¡å‹ç”Ÿæˆä¸åŸå§‹æ–‡æœ¬ç›¸å…³çš„å“åº”ã€‚

## è¯„ä¼°ä¸æ¯”è¾ƒ
è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å°†å®šé‡å’Œå®šæ€§åœ°æ¯”è¾ƒæ¨¡å‹çš„æ¯’æ€§é™ä½æ•ˆæœã€‚ä½¿ç”¨è¯„ä¼°åº“ä¸­çš„toxicityè¯„ä¼°æœºåˆ¶ï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒPPOå‰åæ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ¯’æ€§å¾—åˆ†ã€‚

## ç»“è®º
é€šè¿‡RLHFï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°é™ä½AIæ¨¡å‹çš„æ¯’æ€§ï¼Œä½¿å…¶è¾“å‡ºæ›´åŠ å®‰å…¨å’Œç¬¦åˆäººç±»ä»·å€¼è§‚ã€‚å®éªŒå®¤ç»ƒä¹ ä½¿æˆ‘ä»¬èƒ½å¤Ÿäº²æ‰‹å®è·µè¿™ä¸€è¿‡ç¨‹ï¼Œç†è§£å…¶èƒŒåçš„åŸç†å’ŒæŒ‘æˆ˜ã€‚

---

**æ³¨**ï¼šæœ¬æ–‡ä¸ºç§‘æ™®æ€§è´¨çš„æŠ€æœ¯æ–‡ç« ï¼Œæ—¨åœ¨å‘éä¸“ä¸šè¯»è€…ä»‹ç»RLHFæŠ€æœ¯å¦‚ä½•åº”ç”¨äºé™ä½AIæ¨¡å‹çš„æ¯’æ€§ï¼Œå¹¶æ¦‚è¿°äº†å®éªŒå®¤ç»ƒä¹ çš„æ­¥éª¤å’Œç›®æ ‡ã€‚

---

[åŠ å…¥æˆ‘ä»¬ï¼Œæ¢ç´¢æ›´å¤šAIï¼](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---
