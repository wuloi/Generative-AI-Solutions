# ğŸ“Š æŒæ¡è¡¡é‡ï¼šè§£é”LLMæ€§èƒ½æŒ‡æ ‡

å˜¿ï¼Œæ•°æ®ä¾¦æ¢ä»¬ï¼ğŸ•µï¸â€â™‚ï¸ æ‹¿èµ·ä½ ä»¬çš„æ”¾å¤§é•œï¼Œæˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç¥ç§˜ä¸–ç•Œã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬æ¥è§£ç é‚£äº›æ­ç¤ºä½ å¾®è°ƒæ¨¡å‹çœŸæ­£èƒ½åŠ›çš„æŒ‡æ ‡ã€‚

## ğŸŒŸ æ€§èƒ½å£°æ˜è§£å¯†
å½“æˆ‘ä»¬è¯´ä¸€ä¸ªæ¨¡å‹â€œæ˜¾ç¤ºå‡ºå¾ˆå¤§çš„æ”¹è¿›â€æ—¶ï¼Œè¿™åˆ°åº•æ„å‘³ç€ä»€ä¹ˆï¼Ÿè®©æˆ‘ä»¬ä¸€èµ·æ‰¾å‡ºå¦‚ä½•é‡åŒ–ä½ çš„LLMè¶…è¶Šå…¶é¢„è®­ç»ƒåŸºç¡€æ‰€å–å¾—çš„è¿›æ­¥ã€‚

### ğŸ“ ä¼ ç»ŸæŒ‡æ ‡ï¼šå‡†ç¡®ç‡åŠå…¶ä¼™ä¼´
åœ¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ é¢†åŸŸï¼Œå‡†ç¡®ç‡æ˜¯ç‹è€…ã€‚ä½†åœ¨LLMsçš„é¢†åŸŸé‡Œï¼Œè¾“å‡ºæ˜¯éç¡®å®šæ€§çš„ï¼Œè¯­è¨€æ˜¯å¤æ‚çš„ï¼Œæˆ‘ä»¬éœ€è¦ä¸€å¥—æ–°çš„å·¥å…·ã€‚

## ğŸ“ˆ å‡†ç¡®ç‡ä¹‹å¤–ï¼šå¼•å…¥ROUGEå’ŒBLEU
æ¬¢è¿æ¥åˆ°ROUGEå’ŒBLEUçš„ä¸–ç•Œï¼Œè¯„ä¼°å°†æœ‰ä¸€ä¸ªè¯­è¨€å­¦çš„è½¬å˜ã€‚

### ğŸ“„ ROUGEï¼šæ‘˜è¦è¯„ä¼°çš„è­¦é•¿
ROUGEï¼ˆRecall-Oriented Understudy for Gisting Evaluationï¼‰æ˜¯è¯„ä¼°ç”Ÿæˆæ‘˜è¦è´¨é‡ä¸äººç±»ç”Ÿæˆçš„é»„é‡‘æ ‡å‡†å¯¹æ¯”çš„å¿…å¤‡å·¥å…·ã€‚

### ğŸ” BLEUï¼šç¿»è¯‘ä»»åŠ¡çš„ç›‘å·¥
BLEUï¼ˆBilingual Evaluation Understudyï¼‰æ˜¯ä¸€ç§ç®—æ³•ï¼Œç”¨äºè¯„åˆ¤æœºå™¨ç¿»è¯‘æ–‡æœ¬çš„è´¨é‡ï¼Œå°†å…¶ä¸äººç±»ç¿»è¯‘è¿›è¡Œæ¯”è¾ƒã€‚

## ğŸ”¢ N-gramå’Œå‰ªè¾‘ï¼šæŠ€æœ¯æœ¯è¯­
åœ¨æˆ‘ä»¬æ·±å…¥è®¡ç®—ä¹‹å‰ï¼Œå…ˆç†Ÿæ‚‰ä¸€ä¸‹æœ¯è¯­ï¼šå•gramã€åŒgramå’Œn-gramæ˜¯æˆ‘ä»¬å°†è¦æ£€æŸ¥çš„æ„å»ºå—ã€‚

### ğŸ”¢ ROUGE-1å’ŒROUGE-2ï¼šåŸºç¡€æ„å»ºå—
è¿™äº›æŒ‡æ ‡åˆ†åˆ«æŸ¥çœ‹å•gramå’ŒåŒgramï¼Œè®¡ç®—å¬å›ç‡ã€ç²¾ç¡®åº¦å’ŒF1åˆ†æ•°ï¼Œä»¥è¯„ä¼°ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒæ–‡æœ¬çš„åŒ¹é…ç¨‹åº¦ã€‚

### ğŸ“š ROUGE-Lï¼šæœ€é•¿å…¬å…±å­åºåˆ—
ROUGE-Lé‡‡å–äº†ä¸åŒçš„æ–¹æ³•ï¼Œå¯»æ‰¾ç”Ÿæˆæ–‡æœ¬å’Œå‚è€ƒæ–‡æœ¬ä¹‹é—´çš„æœ€é•¿å…¬å…±å­åºåˆ—ï¼Œè¿›è¡Œæ›´ç»†è‡´çš„è¯„ä¼°ã€‚

## ğŸ“‰ BLEUåˆ†æ•°åˆ†è§£ï¼šN-gramçš„ç²¾ç¡®åº¦
BLEUåˆ†æ•°å¹³å‡äº†å¤šä¸ªn-gramå¤§å°çš„ç²¾ç¡®åº¦ï¼Œæä¾›äº†å¯¹ç¿»è¯‘è´¨é‡çš„å…¨é¢è§†å›¾ã€‚

## ğŸ› ï¸ è¡Œä¸šå·¥å…·ï¼šåº“å’Œå®éªŒå®¤
æŒæ¡äº†ROUGEå’ŒBLEUçš„çŸ¥è¯†ï¼Œä½ å·²ç»å‡†å¤‡å¥½åœ¨ä½ è‡ªå·±æ¨¡å‹è¯„ä¼°ä¸­ä½¿ç”¨è¿™äº›æŒ‡æ ‡ï¼ŒåƒHugging Faceè¿™æ ·çš„åº“è®©å…¥é—¨å˜å¾—å®¹æ˜“ã€‚

## ğŸ”¬ è¶…è¶Šç®€å•åˆ†æ•°ï¼šåŸºå‡†æµ‹è¯•çš„éœ€è¦
è™½ç„¶ROUGEå’ŒBLEUå¾ˆæœ‰ä»·å€¼ï¼Œä½†å®ƒä»¬ä¸æ˜¯æœ€ç»ˆçš„è£å†³ã€‚ä¸ºäº†è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œå‚è€ƒç ”ç©¶äººå‘˜å¼€å‘çš„åŸºå‡†æµ‹è¯•ï¼Œå…¨é¢è¯„ä¼°ä½ çš„æ¨¡å‹èƒ½åŠ›ã€‚

## ğŸ”® æ€»ç»“ï¼šä½ çš„è¯„ä¼°å¯è’™ä¹‹è·¯
ä½ ç°åœ¨æ‹¥æœ‰äº†è§£é”è¡¡é‡ä½ LLMæŒæ¡åº¦çš„æŒ‡æ ‡çš„é’¥åŒ™ã€‚æ˜æ™ºåœ°ä½¿ç”¨è¿™äº›æ¥æ¯”è¾ƒã€å¯¹æ¯”ï¼Œå¹¶æŒç»­æ”¹è¿›ä½ çš„æ¨¡å‹æ€§èƒ½ã€‚

ä¸è¦å¿˜è®°è®¢é˜…ï¼Œæ·±å…¥äº†è§£AIçš„ä¸–ç•Œã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå¼•å¯¼ä½ ç©¿è¶Šæ¨¡å‹è¯„ä¼°çš„å¤æ‚æ™¯è§‚åŠå…¶ä¹‹å¤–ï¼

ğŸ‘‹ ä¸‹æ¬¡è§ï¼Œç»§ç»­è¡¡é‡ï¼Œç»§ç»­æ”¹è¿›ï¼Œæ„¿ä½ çš„æ¨¡å‹æ€»æ˜¯è¶…è¶Šå…¶ä»–ï¼

---

[åŠ å…¥æˆ‘ä»¬ï¼Œè·å–æ›´å¤šå…³äºæ¨¡å‹è¯„ä¼°å’ŒAIå¥¥å¾·èµ›çš„å†…å®¹ï¼](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---

# ğŸ“Š Measuring Mastery: Unlocking the Metrics of LLM Performance

Hey Data Detectives! ğŸ•µï¸â€â™‚ï¸ Grab your magnifying glasses as we sleuth our way through the mysterious world of evaluating Large Language Models (LLMs). Today, we're decoding the metrics that reveal the true prowess of your fine-tuned models.

## ğŸŒŸ Performance Proclamations Demystified
When we say a model "showed a large improvement," what does that really mean? Let's find out how to quantify the strides your LLM has made beyond its pre-trained roots.

### ğŸ“ Traditional Metrics: Accuracy and Friends
In the land of traditional machine learning, accuracy is king. But in the realm of LLMs, where outputs are non-deterministic and language is complex, we need a new set of tools.

## ğŸ“ˆ Beyond Accuracy: Introducing ROUGE and BLEU
Welcome to the world of ROUGE and BLEU, where evaluation gets a linguistic twist.

### ğŸ“„ ROUGE: The Summarization Sheriff
ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is the go-to for assessing the quality of generated summaries against human-generated gold standards.

### ğŸ” BLEU: The Translation Taskmaster
BLEU (Bilingual Evaluation Understudy) is the algorithm that judges the quality of machine-translated text, comparing it to human translations.

## ğŸ”¢ N-grams and Clipping: The Technical Terms
Before we dive into the calculations, let's get familiar with the lingo: unigrams, bigrams, and n-grams are the building blocks we'll examine.

### ğŸ”¢ ROUGE-1 and ROUGE-2: The Basic Building Blocks
These metrics look at unigrams and bigrams, respectively, calculating recall, precision, and F1 scores to evaluate how well generated text matches the reference.

### ğŸ“š ROUGE-L: The Longest Common Subsequence
ROUGE-L takes a different approach, seeking the longest common subsequence between the generated and reference texts for a more nuanced evaluation.

## ğŸ“‰ BLEU Score Breakdown: Precision Across N-grams
The BLEU score averages precision across multiple n-gram sizes, providing a comprehensive view of translation quality.

## ğŸ› ï¸ Tools of the Trade: Libraries and Labs
Armed with knowledge of ROUGE and BLEU, you're ready to put these metrics to work in your own model evaluations, with libraries like Hugging Face making it easy to get started.

## ğŸ”¬ Beyond Simple Scores: The Need for Benchmarks
While ROUGE and BLEU are valuable, they're not the final word. For a thorough evaluation, turn to the benchmarks developed by researchers for a holistic assessment of your model's capabilities.

## ğŸ”® Wrapping Up: Your Path to Evaluation Enlightenment
You now have the keys to unlock the metrics that measure your LLM's mastery. Use these wisely to compare, contrast, and continually improve your models' performance.

Don't forget to subscribe for more adventures in the world of AI. We're here to guide you through the complex landscapes of model evaluation and beyond!

ğŸ‘‹ Until next time, keep measuring, keep refining, and may your models always outperform the rest!

---

[Join us for more on model evaluation and the AI odyssey!](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---

# ç§‘æ™®æŠ€æœ¯æ–‡ç« ï¼šè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ä¸åŸºå‡†

## å¼•è¨€
åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¼€å‘è¿‡ç¨‹ä¸­ï¼Œè¯„ä¼°æ¨¡å‹æ€§èƒ½æ˜¯ä¸€é¡¹é‡è¦ä»»åŠ¡ã€‚æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•é€šè¿‡ä¸åŒçš„æŒ‡æ ‡æ¥é‡åŒ–å¾®è°ƒæ¨¡å‹ç›¸è¾ƒäºé¢„è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½æå‡ã€‚

## æ€§èƒ½è¯„ä¼°çš„æŒ‘æˆ˜
ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ä¸åŒï¼ŒLLMsçš„è¾“å‡ºå…·æœ‰éç¡®å®šæ€§ï¼Œä¸”åŸºäºè¯­è¨€çš„è¯„ä¼°æ›´ä¸ºå¤æ‚ã€‚å› æ­¤ï¼Œéœ€è¦è‡ªåŠ¨åŒ–å’Œç»“æ„åŒ–çš„æ–¹æ³•æ¥è¡¡é‡æ¨¡å‹è¾“å‡ºçš„è´¨é‡ã€‚

## ROUGEå’ŒBLEUæŒ‡æ ‡
ROUGEï¼ˆRecall Oriented Understudy for Gisting Evaluationï¼‰ä¸»è¦ç”¨äºè¯„ä¼°è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦çš„è´¨é‡ï¼Œè€ŒBLEUï¼ˆBilingual Evaluation Understudyï¼‰åˆ™ç”¨äºè¯„ä¼°æœºå™¨ç¿»è¯‘æ–‡æœ¬çš„è´¨é‡ã€‚

## æœ¯è¯­è§£é‡Š
- **Unigram**ï¼šå•ä¸ªè¯ã€‚
- **Bigram**ï¼šä¸¤ä¸ªè¿ç»­è¯ã€‚
- **N-gram**ï¼šè¿ç»­çš„nä¸ªè¯ã€‚

## ROUGEæŒ‡æ ‡çš„è®¡ç®—
ROUGEæŒ‡æ ‡åŒ…æ‹¬ROUGE-1ã€ROUGE-2å’ŒRouge-Lï¼Œåˆ†åˆ«åŸºäº1-gramã€2-gramå’Œæœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆLCSï¼‰æ¥è®¡ç®—å¬å›ç‡ã€ç²¾ç¡®åº¦å’ŒF1åˆ†æ•°ã€‚

### ROUGE-1
åªå…³æ³¨å•ä¸ªè¯çš„åŒ¹é…ï¼Œä¸è€ƒè™‘è¯åºã€‚

### ROUGE-2
è€ƒè™‘è¯å¯¹ï¼ˆbigramsï¼‰çš„åŒ¹é…ï¼Œç®€å•åæ˜ è¯åºã€‚

### Rouge-L
åŸºäºæœ€é•¿å…¬å…±å­åºåˆ—æ¥è¯„ä¼°ï¼Œæ›´å…¨é¢åœ°åæ˜ å¥å­ç»“æ„ã€‚

## BLEUæŒ‡æ ‡çš„è®¡ç®—
BLEUåˆ†æ•°é€šè¿‡å¤šä¸ªn-gramå¤§å°çš„å¹³å‡ç²¾ç¡®åº¦æ¥è®¡ç®—ï¼Œé‡åŒ–ç¿»è¯‘è´¨é‡ã€‚

## è¯„ä¼°æŒ‡æ ‡çš„å±€é™æ€§
- ç®€å•æŒ‡æ ‡å¦‚ROUGE-1å¯èƒ½æ— æ³•å‡†ç¡®åæ˜ å¥å­è´¨é‡ã€‚
- BLEUåˆ†æ•°è™½ç„¶ç›´è§‚ï¼Œä½†å¯èƒ½æ— æ³•å®Œå…¨æ•æ‰ç¿»è¯‘çš„æµç•…æ€§å’Œå‡†ç¡®æ€§ã€‚

## è¯„ä¼°æŒ‡æ ‡çš„æ­£ç¡®ä½¿ç”¨
- ä½¿ç”¨ROUGEè¿›è¡Œæ‘˜è¦ä»»åŠ¡çš„è¯Šæ–­æ€§è¯„ä¼°ã€‚
- ä½¿ç”¨BLEUè¿›è¡Œç¿»è¯‘ä»»åŠ¡çš„è¯„ä¼°ã€‚
- ç»“åˆä½¿ç”¨ä¸åŒçš„æŒ‡æ ‡å’Œè¯„ä¼°åŸºå‡†æ¥å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

## ç»“è¯­
åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ï¼Œå¼€å‘è€…éœ€è¦é‡‡ç”¨ä¸€ç³»åˆ—æŒ‡æ ‡å’ŒåŸºå‡†æ¥å…¨é¢ç†è§£æ¨¡å‹çš„æ€§èƒ½ã€‚ROUGEå’ŒBLEUæä¾›äº†è¯„ä¼°è‡ªåŠ¨æ‘˜è¦å’Œæœºå™¨ç¿»è¯‘è´¨é‡çš„æœ‰æ•ˆå·¥å…·ï¼Œä½†åº”ç»“åˆå…¶ä»–è¯„ä¼°æ–¹æ³•æ¥è·å¾—æ›´å‡†ç¡®çš„æ€§èƒ½è¯„ä¼°ã€‚

---

æœ¬æ–‡ä¸ºè¯»è€…æä¾›äº†è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡å’Œæ–¹æ³•çš„æ·±å…¥ç†è§£ï¼Œå¸®åŠ©ä»–ä»¬åœ¨æ¨¡å‹å¼€å‘å’Œå¾®è°ƒè¿‡ç¨‹ä¸­åšå‡ºæ›´å‡†ç¡®çš„æ€§èƒ½è¯„ä¼°å’Œæ¯”è¾ƒã€‚

---

[åŠ å…¥æˆ‘ä»¬ï¼Œè·å–æ›´å¤šå…³äºæ¨¡å‹è¯„ä¼°å’ŒAIå¥¥å¾·èµ›çš„å†…å®¹ï¼](https://roadmaps.feishu.cn/wiki/RykrwFxPiiU4T7kZ63bc7Lqdnch)

---
